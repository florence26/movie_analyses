{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Film Corpus 2.0\n",
    "# Overview: This corpus is an updated version of the Film Corpus 1.0. It contains complete texts for the scripts of 1068 films in txt files, scraped from imsdb.com on Nov, 2015 using scrapy. It also contains 960 film scripts where the dialog in the film has been separated from the scene descriptions.\n",
    "\n",
    "# The Data: Film scripts are classified by genre,  but one film can be in multiple genres. There are fewer than 1068 separated scripts because we use our own script to automatically separate the dialog and scene descriptions.\n",
    "\n",
    "# Corpus from: https://nlds.soe.ucsc.edu/fc2\n",
    "\n",
    "# Only 10 movies from the genres: Action, Comedy, Drama, Romance, Thriller were selected due to size of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Binary Relevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Performance metric\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_meta = pd.read_csv(\"C:/Users/yeungf8452/MovieSummaries/movie.metadata.tsv\", sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "with open(\"C:/Users/yeungf8452/MovieSummaries/plot_summaries.txt\", 'r', encoding=\"utf8\") as f:\n",
    "       reader = csv.reader(f, dialect='excel-tab') \n",
    "       for row in reader:\n",
    "            plots.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = []\n",
    "plot = []\n",
    "\n",
    "# extract movie Ids and plot summaries\n",
    "for i in plots:\n",
    "  movie_id.append(i[0])\n",
    "  plot.append(i[1])\n",
    "\n",
    "# create dataframe\n",
    "movies = pd.DataFrame({'movie_id': movie_id, 'plot': plot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "movie_meta.columns = [\"movie_id\",1,\"movie_name\",3,4,5,6,7,\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>plot</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Taxi Blues</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\", \"/m/03q4nz\": \"World ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>{\"/m/03btsm8\": \"Action/Adventure\", \"/m/06n90\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>Narasimham</td>\n",
       "      <td>{\"/m/04t36\": \"Musical\", \"/m/02kdv5l\": \"Action\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>The Lemon Drop Kid</td>\n",
       "      <td>{\"/m/06qm3\": \"Screwball comedy\", \"/m/01z4y\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>A Cry in the Dark</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                               plot  \\\n",
       "0  23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1  31186339  The nation of Panem consists of a wealthy Capi...   \n",
       "2  20663735  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3   2231378  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4    595909  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "\n",
       "           movie_name                                              genre  \n",
       "0          Taxi Blues  {\"/m/07s9rl0\": \"Drama\", \"/m/03q4nz\": \"World ci...  \n",
       "1    The Hunger Games  {\"/m/03btsm8\": \"Action/Adventure\", \"/m/06n90\":...  \n",
       "2          Narasimham  {\"/m/04t36\": \"Musical\", \"/m/02kdv5l\": \"Action\"...  \n",
       "3  The Lemon Drop Kid  {\"/m/06qm3\": \"Screwball comedy\", \"/m/01z4y\": \"...  \n",
       "4   A Cry in the Dark  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change datatype of 'movie_id'\n",
    "movie_meta['movie_id'] = movie_meta['movie_id'].astype(str)\n",
    "\n",
    "# merge meta with movies\n",
    "movies = pd.merge(movies, movie_meta[['movie_id', 'movie_name', 'genre']], on = 'movie_id')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an empty list\n",
    "genres = [] \n",
    "\n",
    "# extract genres\n",
    "for i in movies['genre']: \n",
    "  genres.append(list(json.loads(i).values())) \n",
    "\n",
    "# add to 'movies' dataframe  \n",
    "movies['genre_new'] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# remove samples with 0 genre tags\n",
    "movies_new = movies[~(movies['genre_new'].str.len() == 0)]\n",
    "\n",
    "movies_new['clean_plot'] = movies_new['plot'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "movies_new['clean_plot'] = movies_new['clean_plot'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(movies_new['genre_new'])\n",
    "\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(movies_new['genre_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(movies_new['clean_plot'], y, test_size=0.2, random_state=9)\n",
    "\n",
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:75: UserWarning: Label not 48 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:75: UserWarning: Label not 182 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:75: UserWarning: Label not 214 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:75: UserWarning: Label not 245 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "clf = OneVsRestClassifier(lr)\n",
    "\n",
    "# fit model on train data\n",
    "clf.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "y_pred = clf.predict(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Action', 'Drama')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.inverse_transform(y_pred)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers documentation: https://huggingface.co/transformers/\n",
    "# From https://huggingface.co/transformers/task_summary.html - Sequence Classification for sentiment analysis\n",
    "# pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "Downloading: 100%|██████████| 629/629 [00:00<00:00, 210kB/s]\n",
      "Downloading: 100%|██████████| 256M/256M [01:43<00:00, 2.59MB/s]\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 12.0kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 643kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Defaults to distilBERT\n",
    "# Light version of BERT\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier(\"I hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
